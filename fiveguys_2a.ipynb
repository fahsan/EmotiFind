{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# fiveguys_2a.ipynb\n",
    "# Team C: Five Guys: Burgers and Fries\n",
    "# Aditya Jain, Alex Sandoval, Darrell Harvey, and Fasih Ahsan\n",
    "# COM SCI X 450.1 Section 362062\n",
    "# UCLA Extension, Spring 2018\n",
    "# IPython Notebook for Class Project 2b Submission\n",
    "# Script creates an EmotiFind function predictEmotion()\n",
    "# Function input is a UTF-8 .txt file for any article, tweet, etc. Must be in the same folder as this .ipynb. \n",
    "# Function output is standard stream print of predicted emotion values for 8 emotions\n",
    "# Sadness, Anger, Joy, Trust, Fear, Surprise, Disgust, Anticipation\n",
    "# Must also keep in same folder as .ipynb: EmoLex, TrainingSetEmotions, TrainingSetArticles .txt files.\n",
    "# Unzip these files from the submission. \n",
    "# Requires installation of nltk corpus, csv, NumPy, Matplotlib, SciKit-Learn\n",
    "# Version 0.0.1  - 05/13/2018\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "# Import required libraries and packages. \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import default dictionary for dictionary lists, initialize list and dicts. \n",
    "#from collections import defaultdict\n",
    "emotion_dict = defaultdict(list)\n",
    "emolexdatalist= []\n",
    "train_sadness = []\n",
    "train_anger = []\n",
    "train_joy = []\n",
    "train_trust = []\n",
    "train_fear = []\n",
    "train_surprise = []\n",
    "train_disgust = []\n",
    "train_anticipation = []\n",
    "\n",
    "# Open and read the EmoLex into a list of lists. \n",
    "with open(\"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\", \"r\") as emolexdata:\n",
    "    next(emolexdata)\n",
    "    for row in emolexdata:\n",
    "        row = row.strip().split(\"\\t\")\n",
    "        emolexdatalist.append(row)\n",
    "    emolexdata.close()\n",
    "\n",
    "# For each list in the list of lists \n",
    "for line in emolexdatalist:\n",
    "    # If the word is included in the emotion\n",
    "    if line[2] == \"1\":\n",
    "        # And if the emotion is not a sentiment\n",
    "        if (line[1] != 'negative') and (line[1] != 'positive'):\n",
    "            # Add the word to the list of lists\n",
    "            emotion_dict[line[1]].append(line[0])\n",
    "        else:\n",
    "            # Otherwise if it is 0, and if is a sentiment, skip. \n",
    "            continue\n",
    "            \n",
    "#Open and import the training set emotions.txt\n",
    "with open(\"TrainingSetEmotions.txt\", \"r\") as trainingsetemotions:\n",
    "    next(trainingsetemotions)\n",
    "    reader = csv.reader(trainingsetemotions,delimiter='\\t')\n",
    "    for sadness,anger,joy,trust,fear,surprise,disgust,anticipation in reader:\n",
    "        train_sadness.append(sadness)\n",
    "        train_anger.append(anger)\n",
    "        train_joy.append(joy)\n",
    "        train_trust.append(trust)\n",
    "        train_fear.append(fear)\n",
    "        train_surprise.append(surprise)\n",
    "        train_disgust.append(disgust)\n",
    "        train_anticipation.append(anticipation)\n",
    "\n",
    "# @function clean_article()\n",
    "# @input articleName is the .txt file of the article to clean. \n",
    "def clean_article(articleName):\n",
    "    token_frequency_dic = {}\n",
    "    with open(articleName,'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "        # split into words\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "\n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "        # remove remaining tokens that are not alphabetic\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "\n",
    "        # filter out stop words and sort\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "        words.sort()\n",
    "        req = nltk.FreqDist(words)\n",
    "        for k,v in req.items():\n",
    "            token_frequency_dic[str(k)] = v\n",
    "               \n",
    "        return token_frequency_dic\n",
    "\n",
    "    f.close()\n",
    "\n",
    "# @function\n",
    "    #part 1 of checking the words in emption_dict\n",
    "def token_checker_1(emotion_dict, token_frequency):\n",
    "    token_frequency_present = {}\n",
    "    token_frequency_absent = {}\n",
    "    #creating a blank dictionary for each emotion based on emotion_dict\n",
    "    for emotion in emotion_dict:\n",
    "        token_frequency_present[emotion] = {}\n",
    "        \n",
    "    for word in token_frequency: #taking the word \n",
    "        present = False  #internal check to see if the word is present in any of the emotion dicts\n",
    "        for emotion in emotion_dict: # going into sad in the emotion dict\n",
    "            if word in emotion_dict[emotion]: # going into the list of words in sad words\n",
    "                token_frequency_present[emotion][word]= token_frequency[word]\n",
    "                present = True #will change if \n",
    "        if present == False:\n",
    "            token_frequency_absent[word]= token_frequency[word]\n",
    "    return [token_frequency_present,token_frequency_absent]\n",
    "\n",
    "\n",
    "\n",
    "#part 2 of checking the words in the emption_dict\n",
    "def token_checker_2(token_frequency_present,token_frequency_absent,emotion_dict):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    token_frequency_absent_l = {}\n",
    "    for word in token_frequency_absent: #taking the word sorrow\n",
    "        word_lemma = lemmatizer.lemmatize(word)\n",
    "        for word_p in token_frequency_present:\n",
    "            if word_lemma is word_p:\n",
    "                token_frequency_present[word_p] = token_frequency_present[word_p] + token_frequency_absent[word]\n",
    "            else:\n",
    "                token_frequency_absent_l[word_lemma] = token_frequency_absent[word]\n",
    "\n",
    "    [token_frequency_present_2,token_frequency_absent_2] = token_checker_1(emotion_dict,token_frequency_absent_l)\n",
    "\n",
    "    for emotion in token_frequency_present_2:\n",
    "        if emotion == {}:\n",
    "            continue\n",
    "        for word in token_frequency_present_2[emotion]:\n",
    "            token_frequency_present[emotion][word] = token_frequency_present_2[emotion][word]\n",
    "    return [token_frequency_present,token_frequency_absent_2]\n",
    "\n",
    "\n",
    "#part 3 for checking the words in the synonyms:\n",
    "def token_checker_3(token_frequency_present,token_frequency_absent_2,emotion_dict):    \n",
    "    for word in token_frequency_absent_2:\n",
    "        #create a list with all synonyms\n",
    "        syns = wordnet.synsets(word)\n",
    "        syns_words = []\n",
    "        for n in range(len(syns)):\n",
    "            syns_words.append(syns[n].lemmas()[0].name())\n",
    "        #print(syns_words)\n",
    "        # go in each word in syns_words to make comparison\n",
    "        present = False        \n",
    "        token_frequency_absent_3 = {}\n",
    "        for word_s in syns_words:\n",
    "            if present == True:\n",
    "                break\n",
    "                #check if it is token_frequency_present, \n",
    "                #if yes update the frequency and exit all the for loops except the first one\n",
    "            if word_s is token_frequency_present:\n",
    "                token_frequency_present[word_s] = token_frequency_present[word_s] + token_frequency_absent_2[word]\n",
    "                present = True\n",
    "                #print(present)\n",
    "            else:\n",
    "                #if is is absent in token_frequency_present, \n",
    "                #check emotion dictionary and if it is present exit all except first for\n",
    "                for emotion in emotion_dict: # going into sad in the emotion dict\n",
    "                    if word_s in emotion_dict[emotion]: # going into the list of words in sad words\n",
    "                        token_frequency_present[emotion][word]= token_frequency_absent_2[word]\n",
    "                        present = True\n",
    "                        #print(\"present for\", word_s)\n",
    "        #if it is absent in emotion dictionary, add it to token_frequency_present_3\n",
    "        if present == False:\n",
    "            token_frequency_absent_3[word]= token_frequency_absent_2[word]\n",
    "    return [token_frequency_present, token_frequency_absent_3]\n",
    "\n",
    "def create_param(token_frequency_present,token_frequency):    \n",
    "    parameter1 = {}\n",
    "    for emotion in token_frequency_present:\n",
    "        parameter1[emotion] = 0\n",
    "    for emotion in token_frequency_present:\n",
    "        parameter1[emotion] = sum(token_frequency_present[emotion].values())\n",
    "\n",
    "    parameter2 = {}\n",
    "    total_words = sum(token_frequency.values())\n",
    "    for emotion in parameter1:\n",
    "        parameter2[emotion] = parameter1[emotion]/total_words    \n",
    "    return [parameter1, parameter2]\n",
    "    \n",
    "def token_checker(emotion_dict,token_frequency):\n",
    "    [token_frequency_present,token_frequency_absent_1] = token_checker_1(emotion_dict,token_frequency)\n",
    "    #print(\"part 1 token_frequency_present is\", token_frequency_present, \"\\n\")\n",
    "    #print(\"part 1 token_frequency_absent is\", token_frequency_absent_1,\"\\n\")\n",
    "    #print(\"part 1 params are\", create_param(token_frequency_present,token_frequency))\n",
    "    [token_frequency_present, token_frequency_absent_2] = token_checker_2(token_frequency_present,token_frequency_absent_1,emotion_dict)\n",
    "    #print(\"part 2 token_frequency_present is\", token_frequency_present,\"\\n\")\n",
    "    #print(\"part 2 token_frequency_absent is\", token_frequency_absent_2, \"\\n\")\n",
    "    #print(\"part 2 params are\", create_param(token_frequency_present,token_frequency))\n",
    "    [token_frequency_present, token_frequency_absent_3] = token_checker_3(token_frequency_present,token_frequency_absent_2,emotion_dict)\n",
    "    #print(\"part 3 token_frequency_present is\", token_frequency_present, \"\\n\")\n",
    "    #print(\"part 3 token_frequency_absent is\", token_frequency_absent_3, \"\\n\")\n",
    "    #print(\"part 3 params are\", create_param(token_frequency_present,token_frequency))\n",
    "    return create_param(token_frequency_present,token_frequency)\n",
    "    #print(parameter1)\n",
    "    #print(parameter2)\n",
    "\n",
    "def article_parameters(articleName):\n",
    "    token_frequency = clean_article(articleName)\n",
    "    return token_checker(emotion_dict,token_frequency)\n",
    "\n",
    "def predictEmotion(articlename):\n",
    "    trust_testlist = []\n",
    "    fear_testlist = []\n",
    "    sadness_testlist = []\n",
    "    anger_testlist = []\n",
    "    surprise_testlist = []\n",
    "    disgust_testlist = []\n",
    "    joy_testlist = []\n",
    "    anticipation_testlist = []\n",
    "    \n",
    "    trust_trainlist = []\n",
    "    fear_trainlist = []\n",
    "    sadness_trainlist = []\n",
    "    anger_trainlist = []\n",
    "    surprise_trainlist = []\n",
    "    disgust_trainlist = []\n",
    "    joy_trainlist = []\n",
    "    anticipation_trainlist = []\n",
    "    article_reader_list = []\n",
    "    \n",
    "    for i in range(25):\n",
    "       article_reader_list.append(\"train_article\" + str(i + 1) + \".txt\")\n",
    "\n",
    "    for article in article_reader_list:\n",
    "        train_outputs = article_parameters(article)\n",
    "        listofP1 = list(train_outputs[0].values())\n",
    "        listofP2 = list(train_outputs[1].values())\n",
    "        param_merge = [list(each_emot) for each_emot in zip(listofP1, listofP2)]\n",
    "\n",
    "        trust_trainlist.append(param_merge[0])\n",
    "        fear_trainlist.append(param_merge[1])\n",
    "        sadness_trainlist.append(param_merge[2])\n",
    "        anger_trainlist.append(param_merge[3])\n",
    "        surprise_trainlist.append(param_merge[4])\n",
    "        disgust_trainlist.append(param_merge[5])\n",
    "        joy_trainlist.append(param_merge[6])\n",
    "        anticipation_trainlist.append(param_merge[7])\n",
    "    \n",
    "\n",
    "    test_article = article_parameters(articlename)\n",
    "    testlistofP1 = list(test_article[0].values())\n",
    "    testlistofP2 = list(test_article[1].values())\n",
    "    test_param_merge = [list(each_emot) for each_emot in zip(testlistofP1, testlistofP2)]\n",
    "\n",
    "    trust_testlist.append(test_param_merge[0])\n",
    "    fear_testlist.append(test_param_merge[1])\n",
    "    sadness_testlist.append(test_param_merge[2])\n",
    "    anger_testlist.append(test_param_merge[3])\n",
    "    surprise_testlist.append(test_param_merge[4])\n",
    "    disgust_testlist.append(test_param_merge[5])\n",
    "    joy_testlist.append(test_param_merge[6])\n",
    "    anticipation_testlist.append(test_param_merge[7])\n",
    "    \n",
    "    clf = SVR()\n",
    "    sadnessfit = clf.fit(sadness_trainlist, train_sadness)\n",
    "    trustfit = clf.fit(trust_trainlist, train_trust)\n",
    "    fearfit = clf.fit(fear_trainlist, train_fear)\n",
    "    angerfit = clf.fit(anger_trainlist, train_anger)\n",
    "    surprisefit = clf.fit(surprise_trainlist, train_surprise)\n",
    "    disgustfit = clf.fit(disgust_trainlist, train_disgust)\n",
    "    joyfit = clf.fit(joy_trainlist, train_joy)\n",
    "    anticipationfit = clf.fit(anticipation_trainlist, train_anticipation)\n",
    "    \n",
    "    sadval = sadnessfit.predict(sadness_testlist)\n",
    "    trustval = trustfit.predict(trust_testlist)\n",
    "    fearval = fearfit.predict(fear_testlist)\n",
    "    angerval = angerfit.predict(anger_testlist)\n",
    "    surpriseval = surprisefit.predict(surprise_testlist)\n",
    "    disgustval = disgustfit.predict(disgust_testlist)\n",
    "    joyval = joyfit.predict(joy_testlist)\n",
    "    anticipationval = anticipationfit.predict(anticipation_testlist)\n",
    "    \n",
    "    print(\"Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\\n\",\n",
    "         \"Sadness:\", sadval[0], \"\\n\", \n",
    "         \"Anger:\", angerval[0], \"\\n\", \n",
    "          \"Joy:\", joyval[0], \"\\n\",\n",
    "          \"Trust:\", trustval[0], \"\\n\",\n",
    "         \"Fear:\", fearval[0], \"\\n\",\n",
    "         \"Surprise:\", surpriseval[0], \"\\n\",\n",
    "         \"Disgust:\", disgustval[0], \"\\n\",\n",
    "         \"Anticipation:\", anticipationval[0], \"\\n\",\n",
    "         \"Thank you! Please try us again soon!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: -0.07433237432942524 \n",
      " Anger: 0.250053834601244 \n",
      " Joy: 0.09880697571931346 \n",
      " Trust: 0.23585118113484183 \n",
      " Fear: 0.09880697571931346 \n",
      " Surprise: 0.7489239132192381 \n",
      " Disgust: 0.09880697571931346 \n",
      " Anticipation: 0.10022281411770509 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.39950707772081806 \n",
      " Anger: 0.7845356375399681 \n",
      " Joy: 0.2357051357532984 \n",
      " Trust: 0.24727227921377185 \n",
      " Fear: 0.0996744453537744 \n",
      " Surprise: 0.37323015883738736 \n",
      " Disgust: 0.24727173108234368 \n",
      " Anticipation: 0.10009121356669573 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: -0.07407170272543523 \n",
      " Anger: 0.10000166384595949 \n",
      " Joy: 0.24563659580119843 \n",
      " Trust: 0.4000435410883715 \n",
      " Fear: 0.25272418920865497 \n",
      " Surprise: 0.157950246061568 \n",
      " Disgust: 0.24727227697273843 \n",
      " Anticipation: 0.10000166384595949 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.3997024744618408 \n",
      " Anger: 0.3730809122270305 \n",
      " Joy: 0.10007989894735608 \n",
      " Trust: 0.24722306241143802 \n",
      " Fear: 0.771192688417598 \n",
      " Surprise: 0.771192688417598 \n",
      " Disgust: 0.7854174696030649 \n",
      " Anticipation: 0.10008832879415794 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.1703224320470939 \n",
      " Anger: 0.1703224320470939 \n",
      " Joy: 0.18830198649824037 \n",
      " Trust: 0.2273662089794146 \n",
      " Fear: 0.10001739888580988 \n",
      " Surprise: 0.22551530505602937 \n",
      " Disgust: 0.7832732728040744 \n",
      " Anticipation: 0.2998656198325868 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.21141361628257505 \n",
      " Anger: 0.09980818108709183 \n",
      " Joy: 0.10128159479252904 \n",
      " Trust: 0.1579723438310799 \n",
      " Fear: 0.2998683053776662 \n",
      " Surprise: 0.399063141201613 \n",
      " Disgust: -0.07391278084439429 \n",
      " Anticipation: 0.5003597119621018 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.37287008522312554 \n",
      " Anger: 0.14821716666564588 \n",
      " Joy: 0.2579891492363676 \n",
      " Trust: 0.2472722792137737 \n",
      " Fear: 0.29978935299436166 \n",
      " Surprise: 0.09813692071327021 \n",
      " Disgust: 0.1001041834203722 \n",
      " Anticipation: 0.09967469324858846 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.22735730477563074 \n",
      " Anger: 0.22736130241868155 \n",
      " Joy: 0.10016262101618512 \n",
      " Trust: 0.2472722792137737 \n",
      " Fear: 0.37278192445232156 \n",
      " Surprise: 0.3977474484949051 \n",
      " Disgust: 0.24727227921377185 \n",
      " Anticipation: 0.3002189851355311 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.24596703615297671 \n",
      " Anger: 0.1579572201461399 \n",
      " Joy: 0.09910680823515719 \n",
      " Trust: 0.14771697950530294 \n",
      " Fear: 0.7494043235075862 \n",
      " Surprise: 0.2580223128818559 \n",
      " Disgust: 0.1579572201461399 \n",
      " Anticipation: 0.3999702577141327 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.7463910176378676 \n",
      " Anger: 0.10015359630446066 \n",
      " Joy: 0.3732838714909202 \n",
      " Trust: 0.14778608870261095 \n",
      " Fear: 0.04735479966786327 \n",
      " Surprise: 0.7463910176378676 \n",
      " Disgust: 0.10039927653389255 \n",
      " Anticipation: 0.2998746639815261 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.10577971729835162 \n",
      " Anger: 0.7688671020041745 \n",
      " Joy: 0.24299025860803197 \n",
      " Trust: 0.24727227921377185 \n",
      " Fear: 0.2691860744039447 \n",
      " Surprise: 0.39762602358026516 \n",
      " Disgust: 0.22735863102715403 \n",
      " Anticipation: 0.09994396521022797 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.24298970697443095 \n",
      " Anger: 0.2997516301389184 \n",
      " Joy: 0.2613657376288469 \n",
      " Trust: 0.2472722792137737 \n",
      " Fear: 0.10575464230008139 \n",
      " Surprise: 0.09863089955696833 \n",
      " Disgust: 0.23565981214720733 \n",
      " Anticipation: 0.10009121045085007 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.2456367272285975 \n",
      " Anger: 0.15794818357834267 \n",
      " Joy: 0.24727227921040568 \n",
      " Trust: 0.09994394739416829 \n",
      " Fear: 0.25804209966039454 \n",
      " Surprise: 0.24722289824009774 \n",
      " Disgust: 0.24727227697290763 \n",
      " Anticipation: 0.09994394739416829 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.24563625060106348 \n",
      " Anger: 0.2472717305062912 \n",
      " Joy: 0.1580210059132421 \n",
      " Trust: 0.10259639911187629 \n",
      " Fear: 0.2472722769719249 \n",
      " Surprise: 0.24727227921040446 \n",
      " Disgust: 0.24727227921040446 \n",
      " Anticipation: 0.791372743165616 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.373465146775279 \n",
      " Anger: 0.10005224292321419 \n",
      " Joy: 0.7719969709698051 \n",
      " Trust: 0.11025613589756392 \n",
      " Fear: 0.7860434383251704 \n",
      " Surprise: -0.0743206010801179 \n",
      " Disgust: 0.22735294299493186 \n",
      " Anticipation: 0.09993803521526354 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.2459671481293135 \n",
      " Anger: 0.15795369198541548 \n",
      " Joy: 0.37342073951203214 \n",
      " Trust: 0.7736316392414013 \n",
      " Fear: 0.10113589611778975 \n",
      " Surprise: 0.15796828178377675 \n",
      " Disgust: 0.24563705375135517 \n",
      " Anticipation: -0.07432995313645319 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.22734740188284772 \n",
      " Anger: 0.10001614680689674 \n",
      " Joy: -0.07431497505582396 \n",
      " Trust: 0.10271306600140537 \n",
      " Fear: 0.7876526502395473 \n",
      " Surprise: 0.24563698149944657 \n",
      " Disgust: 0.24727227921040598 \n",
      " Anticipation: 0.09996629283261996 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.37310601507647356 \n",
      " Anger: 0.09966222707060884 \n",
      " Joy: 0.24596677731753447 \n",
      " Trust: 0.21136743400901453 \n",
      " Fear: 0.25274514326881287 \n",
      " Surprise: 0.1000662329985457 \n",
      " Disgust: 0.258003992288268 \n",
      " Anticipation: 0.04711957845832748 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.1005173163087813 \n",
      " Anger: 0.1005173163087813 \n",
      " Joy: 0.15795288764923118 \n",
      " Trust: 0.7480506046836454 \n",
      " Fear: 0.7758087986654894 \n",
      " Surprise: 0.10000237347413515 \n",
      " Disgust: 0.15795288764923118 \n",
      " Anticipation: 0.7758087986654894 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.24299184510109795 \n",
      " Anger: 0.09999573023611075 \n",
      " Joy: 0.7832793156814271 \n",
      " Trust: 0.2472722792137737 \n",
      " Fear: 0.39637164380510476 \n",
      " Surprise: 0.22736087522102397 \n",
      " Disgust: 0.7683017447635894 \n",
      " Anticipation: 0.09999573023611075 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.22734853636722438 \n",
      " Anger: 0.15794860735220306 \n",
      " Joy: 0.3999997386354912 \n",
      " Trust: 0.261315774289951 \n",
      " Fear: 0.10000287140262801 \n",
      " Surprise: 0.22734853636722438 \n",
      " Disgust: 0.15794860735220306 \n",
      " Anticipation: 0.09997026285212435 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.04691799373310318 \n",
      " Anger: 0.24596676876729776 \n",
      " Joy: 0.39939123737595605 \n",
      " Trust: 0.09992374295158851 \n",
      " Fear: 0.10084564641462654 \n",
      " Surprise: -0.07411728302689136 \n",
      " Disgust: 0.24596676876729776 \n",
      " Anticipation: 0.09997721795168124 \n",
      " Thank you! Please try us again soon!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.2527388997575681 \n",
      " Anger: 0.09808323648552952 \n",
      " Joy: 0.27993928200168045 \n",
      " Trust: 0.2472722792137737 \n",
      " Fear: 0.2613723976957586 \n",
      " Surprise: 0.7841773606978507 \n",
      " Disgust: 0.1580055991050177 \n",
      " Anticipation: 0.09997703808157646 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.22734140833195002 \n",
      " Anger: 0.24727173056261403 \n",
      " Joy: -0.07327859191698083 \n",
      " Trust: 0.373652478551318 \n",
      " Fear: 0.1579536219402039 \n",
      " Surprise: 0.1579863937507921 \n",
      " Disgust: 0.24727173056261403 \n",
      " Anticipation: 0.3998936717139161 \n",
      " Thank you! Please try us again soon!\n",
      "Thank you for using EmotiFind by the Five Guys! For the article you have selected, the predicted emotions are:\n",
      " Sadness: 0.04689888434483591 \n",
      " Anger: 0.09797982225652957 \n",
      " Joy: 0.2356554646586633 \n",
      " Trust: 0.2472722792137737 \n",
      " Fear: 0.170252376807391 \n",
      " Surprise: 0.04689888434483591 \n",
      " Disgust: 0.2273579619272281 \n",
      " Anticipation: 0.10009986509877888 \n",
      " Thank you! Please try us again soon!\n"
     ]
    }
   ],
   "source": [
    "test_reader_list = []\n",
    "\n",
    "for i in range(25):\n",
    "    test_reader_list.append(\"train_article\" + str(i + 1) + \".txt\")\n",
    "\n",
    "for article in test_reader_list:\n",
    "    predictEmotion(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
